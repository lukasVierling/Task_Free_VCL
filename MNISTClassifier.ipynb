{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms, utils\n",
    "import torchvision.datasets\n",
    "\n",
    "from torch.utils.data import DataLoader,Subset\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.mnist_classifier import MNISTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 55000\n"
     ]
    }
   ],
   "source": [
    "data =  torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "data_test =  torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "eval_idx = torch.randperm(len(data))[:5000]\n",
    "\n",
    "data_eval = Subset(data, eval_idx)\n",
    "train_idx = [i for i in range(len(data)) if i not in eval_idx]\n",
    "\n",
    "data_train = Subset(data, train_idx)\n",
    "\n",
    "print(len(data_eval), len(data_train))\n",
    "\n",
    "train_loader = DataLoader(data_train, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(data_test, batch_size = 256, shuffle=True)\n",
    "eval_loader = DataLoader(data_eval, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval the classifier: 20it [00:00, 26.72it/s]15 [00:00<?, ?it/s]\n",
      "Train the classifier...:   7%|▋         | 1/15 [00:09<02:12,  9.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Evaluating\n",
      "Got : 0.9642 correct predictions on Eval\n",
      "Loss: 85.4907333701849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval the classifier: 20it [00:00, 26.99it/s]\n",
      "Train the classifier...:  13%|█▎        | 2/15 [00:18<02:03,  9.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Evaluating\n",
      "Got : 0.9772 correct predictions on Eval\n",
      "Loss: 18.48391891643405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval the classifier: 20it [00:00, 27.12it/s]\n",
      "Train the classifier...:  20%|██        | 3/15 [00:28<01:53,  9.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Evaluating\n",
      "Got : 0.9832 correct predictions on Eval\n",
      "Loss: 12.697551483288407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval the classifier: 20it [00:00, 26.87it/s]\n",
      "Train the classifier...:  27%|██▋       | 4/15 [00:37<01:44,  9.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Evaluating\n",
      "Got : 0.9842 correct predictions on Eval\n",
      "Loss: 10.052294757217169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval the classifier: 20it [00:00, 26.50it/s]\n",
      "Train the classifier...:  33%|███▎      | 5/15 [00:47<01:35,  9.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Evaluating\n",
      "Got : 0.9836 correct predictions on Eval\n",
      "Loss: 8.143664833158255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval the classifier: 20it [00:00, 26.76it/s]\n",
      "Train the classifier...:  40%|████      | 6/15 [00:57<01:25,  9.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Evaluating\n",
      "Got : 0.9854 correct predictions on Eval\n",
      "Loss: 6.820592971984297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval the classifier: 20it [00:00, 27.17it/s]\n",
      "Train the classifier...:  47%|████▋     | 7/15 [01:06<01:16,  9.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Evaluating\n",
      "Got : 0.9876 correct predictions on Eval\n",
      "Loss: 6.0679896841757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval the classifier: 20it [00:00, 27.04it/s]\n",
      "Train the classifier...:  53%|█████▎    | 8/15 [01:16<01:06,  9.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Evaluating\n",
      "Got : 0.986 correct predictions on Eval\n",
      "Loss: 5.367546751629561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval the classifier: 20it [00:00, 26.95it/s]\n",
      "Train the classifier...:  60%|██████    | 9/15 [01:25<00:57,  9.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Evaluating\n",
      "Got : 0.988 correct predictions on Eval\n",
      "Loss: 4.76151297101751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval the classifier: 20it [00:00, 26.83it/s]\n",
      "Train the classifier...:  67%|██████▋   | 10/15 [01:35<00:47,  9.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Evaluating\n",
      "Got : 0.9868 correct predictions on Eval\n",
      "Loss: 4.078572123777121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval the classifier: 20it [00:00, 26.64it/s]\n",
      "Train the classifier...:  73%|███████▎  | 11/15 [01:44<00:38,  9.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Evaluating\n",
      "Got : 0.9888 correct predictions on Eval\n",
      "Loss: 3.507115508429706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval the classifier: 20it [00:00, 26.66it/s]\n",
      "Train the classifier...:  80%|████████  | 12/15 [01:54<00:28,  9.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Evaluating\n",
      "Got : 0.9852 correct predictions on Eval\n",
      "Loss: 3.149536758195609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval the classifier: 20it [00:00, 26.61it/s]\n",
      "Train the classifier...:  87%|████████▋ | 13/15 [02:04<00:19,  9.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Evaluating\n",
      "Got : 0.9894 correct predictions on Eval\n",
      "Loss: 2.7378638543887064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval the classifier: 20it [00:00, 26.59it/s]\n",
      "Train the classifier...:  93%|█████████▎| 14/15 [02:13<00:09,  9.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Evaluating\n",
      "Got : 0.99 correct predictions on Eval\n",
      "Loss: 2.590119845001027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval the classifier: 20it [00:00, 26.68it/s]\n",
      "Train the classifier...: 100%|██████████| 15/15 [02:23<00:00,  9.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Evaluating\n",
      "Got : 0.9892 correct predictions on Eval\n",
      "Loss: 2.031988272909075\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = MNISTClassifier()\n",
    "device = \"cuda\"\n",
    "epochs = 15\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "model.to(device)\n",
    "# loop over the dataset multiple times\n",
    "for epoch in tqdm(range(epochs), desc=\"Train the classifier...\"):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    #eval on the val set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        # loop over the dataset multiple times\n",
    "        for i, data in tqdm(enumerate(eval_loader, 0), desc=\"Eval the classifier\"):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model.get_probs(inputs) #returns softmaxed output\n",
    "\n",
    "            #get the predicdtion \n",
    "            predictions = torch.argmax(outputs, dim=-1)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "\n",
    "        print('Finished Evaluating')\n",
    "        print(f\"Got : {correct / len(data_eval)} correct predictions on Eval\")\n",
    "\n",
    "        print('Loss: {}'.format(running_loss))\n",
    "\n",
    "    model.train()\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test the classifier: 40it [00:01, 27.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Testing\n",
      "Got : 0.9913 correct predictions on Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = \"cuda\"\n",
    "model.to(device)\n",
    "correct = 0\n",
    "# loop over the dataset multiple times\n",
    "for i, data in tqdm(enumerate(test_loader, 0), desc=\"Test the classifier\"):\n",
    "    inputs, labels = data\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = model.get_probs(inputs) #returns softmaxed output\n",
    "\n",
    "    #get the predicdtion \n",
    "    predictions = torch.argmax(outputs, dim=-1)\n",
    "    correct += (predictions == labels).sum().item()\n",
    "\n",
    "print('Finished Testing')\n",
    "print(f\"Got : {correct / len(data_test)} correct predictions on Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the weights \n",
    "os.mkdir(\"evaluation\")\n",
    "torch.save(model.state_dict(), \"evaluation/trained_classifier\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LoRA Mech Interpret",
   "language": "python",
   "name": "lora_project"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
